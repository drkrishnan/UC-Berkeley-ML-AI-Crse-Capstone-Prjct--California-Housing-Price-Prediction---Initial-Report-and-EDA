{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6240aa2f-adde-42e5-a41c-73f1ae30bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded dataset 'scikit-learn â€“ California Housing Dataset'\n",
      "\n",
      "Numerical Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Categorical Features: []\n",
      "\n",
      "Feature & Task Understanding Stage completed.\n",
      "\n",
      "Data Clean up and Preprocessing Stage completed.\n",
      "\n",
      "Feature Engineering Stage completed.\n",
      "\n",
      "Exploratory Data Analysis Stage Completed, graphical images are stored in /images/initial_report/ folder.\n",
      "\n",
      "Outlier Handling Stage Completed.\n",
      "\n",
      "Base line model definition and evaluation in progress... .\n",
      "\n",
      "ðŸ“Š Baseline Model Performance Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3a9b7 th {\n",
       "  background-color: #4C72B0;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_3a9b7 td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3a9b7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3a9b7_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3a9b7_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_3a9b7_level0_col2\" class=\"col_heading level0 col2\" >MAE</th>\n",
       "      <th id=\"T_3a9b7_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3a9b7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3a9b7_row0_col0\" class=\"data row0 col0\" >Baseline (Median Predictor)</td>\n",
       "      <td id=\"T_3a9b7_row0_col1\" class=\"data row0 col1\" >1.3762</td>\n",
       "      <td id=\"T_3a9b7_row0_col2\" class=\"data row0 col2\" >0.8740</td>\n",
       "      <td id=\"T_3a9b7_row0_col3\" class=\"data row0 col3\" >-0.0502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21ce9c72210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line model evaluation stage Completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Housing Price Prediction Capstone Project\n",
    "# =========================================\n",
    "#\n",
    "# **Author:** Krishnan Ramaswami  \n",
    "# \n",
    "# \n",
    "# ## Summary\n",
    "# Initial setup : Load dataset and inspect structure, Feature and task understanding, Data cleaning and preparation,\n",
    "# Preprocessing and scaling,Feature engineering,Exploratory Data Analysis (EDA),Outlier handling (IQR method),\n",
    "# Baseline model performance calculation\n",
    "\n",
    "# =========================================\n",
    "# Import Libraries\n",
    "# =========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "from math import pi\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Inline plots\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# =========================================\n",
    "# Load and Inspect Dataset\n",
    "# =========================================\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Convert to DataFrame\n",
    "housing_df = pd.DataFrame(housing.data,\n",
    "                             columns=housing.feature_names)\n",
    "housing_df['MedHouseValue'] = pd.Series(housing.target)\n",
    "\n",
    "#display(housing_df.head())\n",
    "#print(housing_df.info())\n",
    "#print(housing_df.describe())\n",
    "#print(housing_df.isnull().sum())\n",
    "print(\"\\nLoaded dataset 'scikit-learn â€“ California Housing Dataset'\\n\")\n",
    "# =========================================\n",
    "# Feature & Task Understanding\n",
    "# =========================================\n",
    "\n",
    "\n",
    "target = 'MedHouseValue'\n",
    "predictors = [col for col in housing_df.columns if col != target]\n",
    "numerical_features = housing_df[predictors].select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "categorical_features = housing_df[predictors].select_dtypes(include=['object','category']).columns.tolist()\n",
    "print(\"Numerical Features:\", numerical_features)\n",
    "print(\"Categorical Features:\", categorical_features)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(housing_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.savefig(\"images/initial_report/Correlation Heatmap.png\")\n",
    "plt.close()\n",
    "print(\"\\nFeature & Task Understanding Stage completed.\\n\")\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Data Clean up and Preprocessing\n",
    "# =========================================\n",
    "\n",
    "\n",
    "X = housing_df[predictors]\n",
    "y = housing_df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Encode categorical features\n",
    "if categorical_features:\n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train[categorical_features]),\n",
    "                                   columns=encoder.get_feature_names_out(categorical_features),\n",
    "                                   index=X_train.index)\n",
    "    X_test_encoded = pd.DataFrame(encoder.transform(X_test[categorical_features]),\n",
    "                                  columns=encoder.get_feature_names_out(categorical_features),\n",
    "                                  index=X_test.index)\n",
    "    X_train = X_train.drop(categorical_features, axis=1).join(X_train_encoded)\n",
    "    X_test = X_test.drop(categorical_features, axis=1).join(X_test_encoded)\n",
    "print(\"Data Clean up and Preprocessing Stage completed.\\n\")\n",
    "# =========================================\n",
    "# Feature Engineering\n",
    "# =========================================\n",
    "\n",
    "X_train['Rooms_per_Household'] = X_train['AveRooms'] / X_train['AveOccup']\n",
    "X_test['Rooms_per_Household'] = X_test['AveRooms'] / X_test['AveOccup']\n",
    "X_train['Bedrooms_per_Room'] = X_train['AveBedrms'] / X_train['AveRooms']\n",
    "X_test['Bedrooms_per_Room'] = X_test['AveBedrms'] / X_test['AveRooms']\n",
    "X_train['Population_per_Household'] = X_train['Population'] / X_train['AveOccup']\n",
    "X_test['Population_per_Household'] = X_test['Population'] / X_test['AveOccup']\n",
    "#all_features = X_train.columns.tolist()\n",
    "print(\"Feature Engineering Stage completed.\\n\")\n",
    "# =========================================\n",
    "# Exploratory Data Analysis (EDA)\n",
    "# =========================================\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "palette = sns.color_palette(\"Set2\")\n",
    "\n",
    "# Histograms\n",
    "housing_df['Rooms_per_Household'] = housing_df['AveRooms'] / housing_df['AveOccup']\n",
    "housing_df['Bedrooms_per_Room'] = housing_df['AveBedrms'] / housing_df['AveRooms']\n",
    "housing_df['Population_per_Household'] = housing_df['Population'] / housing_df['AveOccup']\n",
    "\n",
    "derived_features = ['Rooms_per_Household', 'Bedrooms_per_Room', 'Population_per_Household']\n",
    "all_features = numerical_features + derived_features\n",
    "fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(all_features):\n",
    "    sns.histplot(X_train[feature], bins=30, kde=True, ax=axes[i], color=palette[i % len(palette)])\n",
    "    axes[i].set_title(f'Distribution of {feature}')\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "# Remove the last empty subplot (if features < 12)\n",
    "if len(all_features) < len(axes):\n",
    "    for j in range(len(all_features), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/initial_report/housing_feature_histograms.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Scatter plots\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x=X_train['MedInc'], y=y_train, alpha=0.5, color='royalblue')\n",
    "plt.title(\"Median Income vs Median House Value\")\n",
    "plt.xlabel(\"Median Income (scaled)\")\n",
    "plt.ylabel(\"Median House Value\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/initial_report/median_income_vs_housevalue.png\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x=X_train['Longitude'], y=X_train['Latitude'], hue=y_train, palette='viridis', alpha=0.5)\n",
    "plt.title(\"Geographic Distribution of House Values\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.legend(title=\"MedHouseValue\", bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/initial_report/geographic_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Exploratory Data Analysis Stage Completed, graphical images are stored in /images/initial_report/ folder.\\n\") \n",
    "# =========================================\n",
    "# Outlier Handling\n",
    "# =========================================\n",
    "\n",
    "def cap_outliers(df, features):\n",
    "    capped = df.copy()\n",
    "    for feature in features:\n",
    "        Q1 = df[feature].quantile(0.25)\n",
    "        Q3 = df[feature].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5*IQR\n",
    "        upper = Q3 + 1.5*IQR\n",
    "        capped[feature] = np.where(capped[feature] < lower, lower, capped[feature])\n",
    "        capped[feature] = np.where(capped[feature] > upper, upper, capped[feature])\n",
    "    return capped\n",
    "\n",
    "X_train_capped = cap_outliers(X_train, all_features)\n",
    "X_test_capped = cap_outliers(X_test, all_features)\n",
    "print(\"Outlier Handling Stage Completed.\\n\")\n",
    "# =========================================\n",
    "# Baseline Model(Median Predictor)\n",
    "# =========================================\n",
    "print(\"Base line model definition and evaluation in progress... .\")\n",
    "baseline_pred = np.median(y_train)\n",
    "baseline_mse = mean_squared_error(y_test, [baseline_pred]*len(y_test))\n",
    "baseline_mae = mean_absolute_error(y_test, [baseline_pred]*len(y_test))\n",
    "baseline_r2 = r2_score(y_test, [baseline_pred]*len(y_test))\n",
    "baseline_results = pd.DataFrame({\n",
    "    'Model': ['Baseline (Median Predictor)'],\n",
    "    'MSE': [baseline_mse],\n",
    "    'MAE': [baseline_mae],\n",
    "    'R2': [baseline_r2]\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ“Š Baseline Model Performance Summary\")\n",
    "display(baseline_results.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('background-color', '#4C72B0'), ('color', 'white'), ('font-weight', 'bold')]},\n",
    "     {'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    ").format({'MSE': '{:.4f}', 'MAE': '{:.4f}', 'R2': '{:.4f}'}))\n",
    "print(\"Base line model evaluation stage Completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199a4163-7d4b-4153-82f6-daee0a4d3a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Initial Regression Models Performance Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e916b th {\n",
       "  background-color: #4C72B0;\n",
       "  color: white;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_e916b td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e916b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e916b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e916b_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_e916b_level0_col2\" class=\"col_heading level0 col2\" >MAE</th>\n",
       "      <th id=\"T_e916b_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e916b_level0_row0\" class=\"row_heading level0 row0\" >3</th>\n",
       "      <td id=\"T_e916b_row0_col0\" class=\"data row0 col0\" >Random Forest</td>\n",
       "      <td id=\"T_e916b_row0_col1\" class=\"data row0 col1\" >0.2711</td>\n",
       "      <td id=\"T_e916b_row0_col2\" class=\"data row0 col2\" >0.3445</td>\n",
       "      <td id=\"T_e916b_row0_col3\" class=\"data row0 col3\" >0.7931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e916b_level0_row1\" class=\"row_heading level0 row1\" >4</th>\n",
       "      <td id=\"T_e916b_row1_col0\" class=\"data row1 col0\" >Gradient Boosting</td>\n",
       "      <td id=\"T_e916b_row1_col1\" class=\"data row1 col1\" >0.2989</td>\n",
       "      <td id=\"T_e916b_row1_col2\" class=\"data row1 col2\" >0.3772</td>\n",
       "      <td id=\"T_e916b_row1_col3\" class=\"data row1 col3\" >0.7719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e916b_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "      <td id=\"T_e916b_row2_col0\" class=\"data row2 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_e916b_row2_col1\" class=\"data row2 col1\" >0.4675</td>\n",
       "      <td id=\"T_e916b_row2_col2\" class=\"data row2 col2\" >0.5048</td>\n",
       "      <td id=\"T_e916b_row2_col3\" class=\"data row2 col3\" >0.6432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e916b_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_e916b_row3_col0\" class=\"data row3 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_e916b_row3_col1\" class=\"data row3 col1\" >0.4675</td>\n",
       "      <td id=\"T_e916b_row3_col2\" class=\"data row3 col2\" >0.5051</td>\n",
       "      <td id=\"T_e916b_row3_col3\" class=\"data row3 col3\" >0.6432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e916b_level0_row4\" class=\"row_heading level0 row4\" >2</th>\n",
       "      <td id=\"T_e916b_row4_col0\" class=\"data row4 col0\" >Decision Tree</td>\n",
       "      <td id=\"T_e916b_row4_col1\" class=\"data row4 col1\" >0.5281</td>\n",
       "      <td id=\"T_e916b_row4_col2\" class=\"data row4 col2\" >0.4775</td>\n",
       "      <td id=\"T_e916b_row4_col3\" class=\"data row4 col3\" >0.5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e916b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e916b_row5_col0\" class=\"data row5 col0\" >KNN Regressor</td>\n",
       "      <td id=\"T_e916b_row5_col1\" class=\"data row5 col1\" >0.6741</td>\n",
       "      <td id=\"T_e916b_row5_col2\" class=\"data row5 col2\" >0.6192</td>\n",
       "      <td id=\"T_e916b_row5_col3\" class=\"data row5 col3\" >0.4855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21cd9860f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================================\n",
    "#  Regression Model Comparison (Initial Models)\n",
    "# =========================================\n",
    "# \n",
    "# After establishing a baseline (median predictor), this section introduces several \n",
    "# standard regression models â€” Linear Regression, Ridge, Decision Tree, Random Forest, \n",
    "# Gradient Boosting, and KNN â€” for initial performance evaluation. \n",
    "# These serve as the first machine learning benchmarks against which future \n",
    "# optimized and tuned models will be compared.\n",
    "\n",
    "#\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    \"KNN Regressor\": KNeighborsRegressor(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_capped, y_train)\n",
    "    y_pred = model.predict(X_test_capped)\n",
    "    results.append([name,\n",
    "                    mean_squared_error(y_test, y_pred),\n",
    "                    mean_absolute_error(y_test, y_pred),\n",
    "                    r2_score(y_test, y_pred)])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Model','MSE','MAE','R2'])\n",
    "results_df.sort_values('R2', ascending=False, inplace=True)\n",
    "print(\"\\nðŸ“ˆ Initial Regression Models Performance Summary\")\n",
    "display(results_df.style.set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('background-color', '#4C72B0'), ('color', 'white'), ('font-weight', 'bold')]},\n",
    "     {'selector': 'td', 'props': [('text-align', 'center')]}]\n",
    ").format({'MSE': '{:.4f}', 'MAE': '{:.4f}', 'R2': '{:.4f}'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5058f3d-71ba-4b6c-b5c5-3e43bc3c6cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
